{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '10': 1, '11': 2, '12': 3, '13': 4, '14': 5, '15': 6, '16': 7, '17': 8, '18': 9, '19': 10, '2': 11, '20': 12, '21': 13, '22': 14, '23': 15, '24': 16, '25': 17, '26': 18, '27': 19, '28': 20, '29': 21, '3': 22, '30': 23, '31': 24, '32': 25, '33': 26, '34': 27, '35': 28, '36': 29, '37': 30, '38': 31, '39': 32, '4': 33, '40': 34, '41': 35, '42': 36, '43': 37, '44': 38, '45': 39, '46': 40, '47': 41, '48': 42, '49': 43, '5': 44, '50': 45, '51': 46, '52': 47, '53': 48, '54': 49, '55': 50, '56': 51, '57': 52, '58': 53, '59': 54, '6': 55, '60': 56, '61': 57, '7': 58, '8': 59, '9': 60}\n",
      "12200\n"
     ]
    }
   ],
   "source": [
    "imagepaths = []\n",
    "categories_set = set()\n",
    "for root, dirs, files in os.walk(\"dataset UFMA\", topdown=False): \n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        #if name.startswith('c'):\n",
    "        #    continue\n",
    "        if path.upper().endswith(\"BMP\"): # We want only the images\n",
    "            imagepaths.append(path)\n",
    "            categories_set.add(os.path.split(root)[1])\n",
    "categories_list = list(sorted(categories_set))\n",
    "\n",
    "categories = dict(zip(categories_list, range(len(categories_list))))\n",
    "print(categories)\n",
    "\n",
    "print(len(imagepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12200, 180, 185, 1), (12200,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "train_or_test = []\n",
    "append_X = X.append\n",
    "append_y = y.append\n",
    "append_train_or_test = train_or_test.append\n",
    "for path in imagepaths:\n",
    "    img = cv2.imread(path) # Reads image and returns np.array\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (GRAY)\n",
    "    img = cv2.resize(img, (185, 180)) # Reduce image size so training can be faster\n",
    "    append_X(img)\n",
    "\n",
    "    # Processing label in image path\n",
    "    path2, category = os.path.split(os.path.split(path)[0])\n",
    "    append_train_or_test(os.path.split(path2)[1])\n",
    "    label = categories[category]\n",
    "    append_y(label)\n",
    "\n",
    "# Turn X and y into np.array to speed up train_test_split\n",
    "X = np.array(X, dtype=\"uint8\")\n",
    "X = X.reshape(len(imagepaths), 180, 185, 1) # Needed to reshape so CNN knows it's different images\n",
    "y = np.array(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6100,  6101,  6102, ..., 12197, 12198, 12199], dtype=int64),\n",
       " array([   0,    1,    2, ..., 6097, 6098, 6099], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_or_te = np.array(train_or_test)\n",
    "train, = np.where(tr_or_te == 'grpotrain')\n",
    "test, = np.where(tr_or_te == 'grpotest')\n",
    "train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "np.save(f\"UFMA_K_Fold/train_UFMA_{i:02d}.npy\", train)\n",
    "np.save(f\"UFMA_K_Fold/test_UFMA_{i:02d}.npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"raw_X_UFMA3.npy\", X)\n",
    "np.save(\"raw_y_UFMA3.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_x = open(\"raw_X_UFMA.npy\", 'rb')\n",
    "fp_y = open(\"raw_y_UFMA.npy\", 'rb')\n",
    "fp_x2 = open(\"raw_X_UFMA2.npy\", 'rb')\n",
    "fp_y2 = open(\"raw_y_UFMA.npy\", 'rb')\n",
    "fp_x.read() == fp_x2.read(), fp_y.read() == fp_y2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_x.close()\n",
    "fp_x2.close()\n",
    "fp_y.close()\n",
    "fp_y2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train, test) in enumerate(kfold.split(X, y), 1):\n",
    "    np.save(f\"UFMA_K_Fold/train_UFMA_{i:02d}.npy\", train)\n",
    "    np.save(f\"UFMA_K_Fold/test_UFMA_{i:02d}.npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
