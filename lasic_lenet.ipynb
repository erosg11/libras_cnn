{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\eros\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split # Helps with organizing data for training\n",
    "from sklearn.metrics import confusion_matrix # Helps present results as a confusion-matrix\n",
    "\n",
    "print(tf.__version__)\n",
    "from keras.applications.vgg19 import VGG19 as VGG16\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 0, '2': 1, '4': 2, '5': 3, '7': 4, '9': 5, 'A': 6, 'Adulto': 7, 'America': 8, 'Aviao': 9, 'B': 10, 'C': 11, 'Casa': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'Gasolina': 17, 'I': 18, 'Identidade': 19, 'Junto': 20, 'L': 21, 'Lei': 22, 'M': 23, 'N': 24, 'O': 25, 'P': 26, 'Palavra': 27, 'Pedra': 28, 'Pequeno': 29, 'Q': 30, 'R': 31, 'S': 32, 'T': 33, 'U': 34, 'V': 35, 'Verbo': 36, 'W': 37, 'X': 38, 'Y': 39}\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "keras.backend.set_session(session)\n",
    "\n",
    "imagepaths = []\n",
    "categories_set = set()\n",
    "\n",
    "# Go through all the files and subdirectories inside a folder and save path to images inside list\n",
    "for root, dirs, files in os.walk(\"Folds_Dataset_Final\", topdown=False): \n",
    "    for name in files:\n",
    "        path = os.path.join(root, name)\n",
    "        if name.startswith('c'):\n",
    "            continue\n",
    "        if path.endswith(\"PNG\"): # We want only the images\n",
    "            imagepaths.append(path)\n",
    "            categories_set.add(os.path.split(root)[1])\n",
    "\n",
    "categories_list = list(sorted(categories_set))\n",
    "\n",
    "categories = dict(zip(categories_list, range(len(categories_list))))\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "Images loaded:  4800\n",
      "Labels loaded:  4800\n"
     ]
    }
   ],
   "source": [
    "print(len(imagepaths)) # If > 0, then a PNG image was loaded\n",
    "size = 50, 50\n",
    "X = [] # Image data\n",
    "y = [] # Labels\n",
    "\n",
    "# Loops through imagepaths to load images and labels into arrays\n",
    "for path in imagepaths:\n",
    "    img = cv2.imread(path) # Reads image and returns np.array\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Converts into the corret colorspace (GRAY)\n",
    "    img = cv2.resize(img, size) # Reduce image size so training can be faster\n",
    "    X.append(img)\n",
    "\n",
    "    # Processing label in image path\n",
    "    category = os.path.split(os.path.split(path)[0])[1]\n",
    "    label = categories[category]\n",
    "    y.append(label)\n",
    "\n",
    "# Turn X and y into np.array to speed up train_test_split\n",
    "X = np.array(X, dtype=\"uint8\")\n",
    "X = X.reshape(len(imagepaths), *size, 1) # Needed to reshape so CNN knows it's different images\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Images loaded: \", len(X))\n",
    "print(\"Labels loaded: \", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Folds_Dataset_Final\\Fold1\\1\\0.PNG\n",
      "Train on 3360 samples, validate on 1440 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 3.6934 - accuracy: 0.0964 - val_loss: 2.4552 - val_accuracy: 0.2674\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.6930 - accuracy: 0.4905 - val_loss: 0.8767 - val_accuracy: 0.7944\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.6686 - accuracy: 0.7982 - val_loss: 0.3281 - val_accuracy: 0.9222\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.3397 - accuracy: 0.8979 - val_loss: 0.1714 - val_accuracy: 0.9569\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.2153 - accuracy: 0.9342 - val_loss: 0.1059 - val_accuracy: 0.9708\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.1281 - accuracy: 0.9589 - val_loss: 0.1246 - val_accuracy: 0.9701\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.1013 - accuracy: 0.9670 - val_loss: 0.0993 - val_accuracy: 0.9785\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0902 - accuracy: 0.9699 - val_loss: 0.0877 - val_accuracy: 0.9806\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0661 - accuracy: 0.9810 - val_loss: 0.0654 - val_accuracy: 0.9806\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0559 - accuracy: 0.9824 - val_loss: 0.1279 - val_accuracy: 0.9743\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0707 - accuracy: 0.9789 - val_loss: 0.0672 - val_accuracy: 0.9833\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0431 - accuracy: 0.9863 - val_loss: 0.0544 - val_accuracy: 0.9875\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.0495 - val_accuracy: 0.9896\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0424 - accuracy: 0.9851 - val_loss: 0.0777 - val_accuracy: 0.9896\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0361 - accuracy: 0.9914 - val_loss: 0.0759 - val_accuracy: 0.9819\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0777 - accuracy: 0.9795 - val_loss: 0.0427 - val_accuracy: 0.9917\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0280 - accuracy: 0.9899 - val_loss: 0.0354 - val_accuracy: 0.9937\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.0285 - val_accuracy: 0.9951\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0303 - accuracy: 0.9914 - val_loss: 0.0415 - val_accuracy: 0.9917\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0142 - accuracy: 0.9946 - val_loss: 0.0790 - val_accuracy: 0.9875\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0238 - accuracy: 0.9929 - val_loss: 0.0480 - val_accuracy: 0.9924\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0478 - val_accuracy: 0.9931\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0458 - val_accuracy: 0.9903\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0287 - accuracy: 0.9929 - val_loss: 0.0594 - val_accuracy: 0.9875\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0502 - val_accuracy: 0.9903\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0425 - accuracy: 0.9902 - val_loss: 0.0718 - val_accuracy: 0.9861\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.0472 - val_accuracy: 0.9931\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.1039 - accuracy: 0.9723 - val_loss: 0.0667 - val_accuracy: 0.9882\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0601 - accuracy: 0.9824 - val_loss: 0.0539 - val_accuracy: 0.9931\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0252 - accuracy: 0.9935 - val_loss: 0.0745 - val_accuracy: 0.9868\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0245 - accuracy: 0.9943 - val_loss: 0.0904 - val_accuracy: 0.9847\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0670 - val_accuracy: 0.9903\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0607 - accuracy: 0.9845 - val_loss: 0.1196 - val_accuracy: 0.9771\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0581 - val_accuracy: 0.9917\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.0455 - val_accuracy: 0.9924\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.0553 - val_accuracy: 0.9910\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0441 - accuracy: 0.9890 - val_loss: 0.0467 - val_accuracy: 0.9931\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0623 - val_accuracy: 0.9903\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1122 - accuracy: 0.9714 - val_loss: 0.0594 - val_accuracy: 0.9896\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0767 - val_accuracy: 0.9868\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0646 - val_accuracy: 0.9882\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.0828 - val_accuracy: 0.9847\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0401 - val_accuracy: 0.9944\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0288 - val_accuracy: 0.9958\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0269 - val_accuracy: 0.9972\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0317 - val_accuracy: 0.9951\n",
      "Epoch 47/100\n",
      " - 0s - loss: 7.9281e-04 - accuracy: 0.9997 - val_loss: 0.0225 - val_accuracy: 0.9965\n",
      "Epoch 48/100\n",
      " - 0s - loss: 3.4178e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9972\n",
      "Epoch 49/100\n",
      " - 0s - loss: 3.9885e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9958\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0271 - val_accuracy: 0.9972\n",
      "Epoch 51/100\n",
      " - 0s - loss: 4.7645e-04 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9979\n",
      "Epoch 52/100\n",
      " - 0s - loss: 2.9591e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9986\n",
      "Epoch 53/100\n",
      " - 0s - loss: 9.9368e-04 - accuracy: 0.9997 - val_loss: 0.0247 - val_accuracy: 0.9965\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0044 - accuracy: 0.9979 - val_loss: 0.0364 - val_accuracy: 0.9951\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0455 - val_accuracy: 0.9958\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0599 - val_accuracy: 0.9910\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1218 - val_accuracy: 0.9771\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0609 - accuracy: 0.9833 - val_loss: 0.1288 - val_accuracy: 0.9806\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.0671 - val_accuracy: 0.9896\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0210 - accuracy: 0.9952 - val_loss: 0.0916 - val_accuracy: 0.9896\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.0860 - val_accuracy: 0.9861\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0305 - accuracy: 0.9899 - val_loss: 0.1073 - val_accuracy: 0.9868\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0408 - accuracy: 0.9884 - val_loss: 0.0447 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0206 - accuracy: 0.9943 - val_loss: 0.0890 - val_accuracy: 0.9861\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.0876 - val_accuracy: 0.9882\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.0733 - val_accuracy: 0.9889\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0239 - accuracy: 0.9946 - val_loss: 0.0921 - val_accuracy: 0.9819\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.0774 - val_accuracy: 0.9889\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0436 - accuracy: 0.9890 - val_loss: 0.2299 - val_accuracy: 0.9653\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0540 - accuracy: 0.9875 - val_loss: 0.1018 - val_accuracy: 0.9833\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0252 - accuracy: 0.9943 - val_loss: 0.1028 - val_accuracy: 0.9924\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0506 - accuracy: 0.9899 - val_loss: 0.0662 - val_accuracy: 0.9875\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0500 - accuracy: 0.9872 - val_loss: 0.0699 - val_accuracy: 0.9924\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0193 - accuracy: 0.9964 - val_loss: 0.0530 - val_accuracy: 0.9903\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.0782 - val_accuracy: 0.9924\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0650 - val_accuracy: 0.9937\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0591 - val_accuracy: 0.9917\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1034 - val_accuracy: 0.9882\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0622 - val_accuracy: 0.9937\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0589 - val_accuracy: 0.9937\n",
      "Epoch 81/100\n",
      " - 0s - loss: 9.8253e-04 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9937\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0011 - accuracy: 0.9991 - val_loss: 0.0701 - val_accuracy: 0.9917\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.0738 - val_accuracy: 0.9944\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0721 - val_accuracy: 0.9931\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0535 - val_accuracy: 0.9937\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0752 - val_accuracy: 0.9896\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0364 - accuracy: 0.9908 - val_loss: 0.1184 - val_accuracy: 0.9882\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0653 - val_accuracy: 0.9917\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0789 - val_accuracy: 0.9903\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0482 - accuracy: 0.9905 - val_loss: 0.0688 - val_accuracy: 0.9924\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0340 - accuracy: 0.9914 - val_loss: 0.0743 - val_accuracy: 0.9931\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.0656 - val_accuracy: 0.9924\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.0686 - val_accuracy: 0.9917\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.0601 - val_accuracy: 0.9903\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0477 - val_accuracy: 0.9944\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9917\n",
      "Epoch 97/100\n",
      " - 0s - loss: 1.8856e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9924\n",
      "Epoch 98/100\n",
      " - 0s - loss: 4.2703e-04 - accuracy: 0.9997 - val_loss: 0.0590 - val_accuracy: 0.9944\n",
      "Epoch 99/100\n",
      " - 0s - loss: 8.8182e-04 - accuracy: 0.9997 - val_loss: 0.0623 - val_accuracy: 0.9917\n",
      "Epoch 100/100\n",
      " - 0s - loss: 9.5937e-04 - accuracy: 0.9997 - val_loss: 0.0650 - val_accuracy: 0.9910\n",
      "1440/1440 [==============================] - 0s 55us/step\n",
      "Test accuracy: 99.10%\n"
     ]
    }
   ],
   "source": [
    "print(y[0], imagepaths[0]) # Debugging\n",
    "\n",
    "ts = 0.3 # Percentage of images that we want to use for testing. The rest is used for training.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, random_state=42)\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "img_height,img_width = size\n",
    "num_classes = len(categories)\n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(img_height, img_width, 1))) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(len(categories), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', # Optimization routine, which tells the computer how to adjust the parameter values to minimize the loss function.\n",
    "          loss='sparse_categorical_crossentropy', # Loss function, which tells us how bad our predictions are.\n",
    "          metrics=['accuracy']) # List of metrics to be evaluated by the model during training and testing.\n",
    "# earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=2, validation_data=(X_test, y_test), callbacks=[mcp_save,])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test accuracy: {test_acc*100:2.2f}%')\n",
    "\n",
    "predictions = model.predict(X_test) # Make predictions towards the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1a7a56c7c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.argmax(predictions, axis=1) # Transform predictions into 1-D array with label number\n",
    "\n",
    "df = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "         columns=[f\"Predicted {x}\" for x in categories_list ],\n",
    "         index=[f\"Actual {x}\" for x in categories_list ])\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(5, 4), dpi= 100)\n",
    "heatmap = axis.pcolor(df.values, cmap=plt.cm.RdYlGn)\n",
    "plt.colorbar(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('heatmap_lasic_lenet_dropout')\n",
    "\n",
    "df.to_csv('lasic_results_lenet_dropout.csv')\n",
    "\n",
    "model.save('Lasic_lenet_dropout.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
